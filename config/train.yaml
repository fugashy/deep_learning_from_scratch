neural_network:
  # MNIST
  input_size: 784
  output_size: 10

  hidden_layer_num: 1
  hidden_size: 50

  # relu or sigmoid
  activation: relu

  # relu or sigmoid or xavier or he or float
  weight_init_std: 0.01
  weight_decay_lambda: 0

optimizer:
# SGD
# type: sgd
# learning_rate: 0.1

# Momentum SGD
# type: momentum_sgd
# learning_rate: 0.1
# momentum: 0.9

# AdaGrad
# type: adagrad
# learning_rate: 0.1

# ADAM
  type: adam
  learning_rate: 0.001
  beta1: 0.9
  beta2: 0.999

train:
  iter_num: 10000
  batch_size: 100

plot: True
