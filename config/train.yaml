neural_network:
  # MNIST
  input_size: 784
  output_size: 10

  hidden_layer_num: 1
  hidden_size: 50

  # relu or sigmoid
  activation: relu

  # relu or sigmoid or xavier or he or float
  weight_init_std: he
  weight_decay_lambda: 0

  with_batch_normalization: True

  dropout:
    use: True
    ratio: 0.5

optimizer:
# SGD
# type: sgd
# learning_rate: 0.1

# Momentum SGD
# type: momentum_sgd
# learning_rate: 0.1
# momentum: 0.9

# AdaGrad
# type: adagrad
# learning_rate: 0.1

# ADAM
  type: adam
  learning_rate: 0.001
  beta1: 0.9
  beta2: 0.999

trainer:
  epochs: 20
  mini_batch_size: 100
  # 0 means the config is disable
  evaluate_sample_num_per_epoch: 0
  verbose: True

plot:
  acc: True
  loss: True
  dnn_params: False
