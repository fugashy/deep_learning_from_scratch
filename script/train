#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import sys, os
import pathlib
p = pathlib.Path(os.path.dirname(__file__) + '/..')
root_dir_path = str(p.resolve())
sys.path.append(root_dir_path)
import numpy as np
import src.mnist as mnist
import src.nn as nn
import src.optimizer as optimizer
import src.plot as plot

import yaml


if __name__ == '__main__':
    fd = open(root_dir_path + '/config/train.yaml')
    yaml_node = yaml.load(fd)

    network = nn.create_multilayer_network(yaml_node['neural_network'])
    opt = optimizer.create(yaml_node['optimizer'])

    (x_train, t_train), (x_test, t_test) = mnist.load_mnist(one_hot_label=True)

    # 画像枚数
    train_size = x_train.shape[0]

    # ビューア
    plot_conf = yaml_node['plot']
    acc_plotter = None
    loss_plotter = None
    param_plotter = None
    if plot_conf['acc']:
        acc_plotter = plot.SimplePlotter(
                'Accuracy', label=('epoch', 'accuracy[%]'), y_range=(-0.1, 1.1))
    if plot_conf['loss']:
        loss_plotter = plot.SimplePlotter(
                'Loss', label=('num', 'loss'), y_range=(-0.1, 1.1))
    if plot_conf['dnn_params']:
        param_plotter = plot.NeuralNetworkParamVisualizer(network.params)

    train_loss_list = []
    train_acc_list = []
    test_acc_list = []

    iter_num = yaml_node['train']['iter_num']
    batch_size = yaml_node['train']['batch_size']
    iter_per_epoch = max(train_size / batch_size, 1)
    for i in range(iter_num):
        # 全データからランダムでバッチサイズ分のデータを得る
        batch_mask = np.random.choice(train_size, batch_size)
        x_batch = x_train[batch_mask]
        t_batch = t_train[batch_mask]

        # 誤差逆伝搬法によって勾配を求める
        grad = network.gradient(x_batch, t_batch)

        # ネットワークの重みを更新する
        # 参照渡しのため、networkのメンバが更新される
        params = network.params
        opt.update(params, grad)

        # 順方向の処理を走らせてエラーを得る
        loss = network.loss(x_batch, t_batch)
        train_loss_list.append(loss)

        # エポック毎に精度の確認
        if i % iter_per_epoch == 0:
            if param_plotter is not None:
                param_plotter.plot()

            train_acc = network.accuracy(x_train, t_train)
            test_acc = network.accuracy(x_test, t_test)
            train_acc_list.append(train_acc)
            test_acc_list.append(test_acc)
            print('batch num: {0}\n\ttrain_acc: {1}, test_acc:{2}'.format(
                i / iter_per_epoch, train_acc, test_acc))

            if acc_plotter is not None:
                acc_plotter.plot([train_acc_list, test_acc_list])
            if loss_plotter is not None:
                loss_plotter.plot(train_loss_list)

    print('Training is done')
    input()
